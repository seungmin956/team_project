# utils/processors/filter_criteria_extractor.py - ì´ ì½”ë“œëŠ” ìì—°ì–´ ì§ˆë¬¸ì—ì„œ í•„í„°ë§ ì¡°ê±´ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤

import json
import re
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

class FilterCriteriaExtractor:
    """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ChromaDB ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¡°ê±´ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, vectorstore=None):
        self.vectorstore = vectorstore
        self.llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
        
        # ë©”íƒ€ë°ì´í„° í•„ë“œë³„ ë§¤í•‘ ì •ë³´
        self.field_mappings = {
            "recall_class": {
                "field": "class",
                "values": ["I", "II", "III"],
                "keywords": ["í´ë˜ìŠ¤", "ë“±ê¸‰", "class", "ê¸‰", "ì‹¬ê°ë„"]
            },
            "ont_food_type": {
                "field": "ont_food_type", 
                "values": ["Seafood Products", "Livestock Products", "Dairy Products", "Bakery Products", "Beverages"],
                "keywords": ["ìˆ˜ì‚°ë¬¼", "í•´ì‚°ë¬¼", "ìœ¡ë¥˜", "ìœ ì œí’ˆ", "ë¹µë¥˜", "ê³¼ìë¥˜", "ìŒë£Œ", "seafood", "livestock", "dairy", "bakery"]
            },
            "ont_product_state": {
                "field": "ont_product_state",
                "values": ["Refrigerated", "Frozen", "Cooked Food", "Raw", "Dried"],
                "keywords": ["ëƒ‰ì¥", "ëƒ‰ë™", "ì¡°ë¦¬", "ìµíŒ", "ìƒ", "ê±´ì¡°", "refrigerated", "frozen", "cooked", "raw", "dried"]
            },
            "ont_recall_reason": {
                "field": "ont_recall_reason",
                "values": ["Bacterial Contamination", "Allergen Mislabeling", "Foreign Object", "Chemical Contamination"],
                "keywords": ["ì„¸ê· ", "ë°•í…Œë¦¬ì•„", "ì•Œë ˆë¥´ê²", "ë¼ë²¨ë§", "ì´ë¬¼ì§ˆ", "í™”í•™", "bacterial", "allergen", "labeling", "foreign", "chemical"]
            },
            "ont_contaminant": {
                "field": "ont_contaminant",
                "values": ["Salmonella", "Listeria", "E.coli", "Clostridium botulinum"],
                "keywords": ["ì‚´ëª¨ë„¬ë¼", "ë¦¬ìŠ¤í…Œë¦¬ì•„", "ëŒ€ì¥ê· ", "ë³´íˆ´ë¦¬ëˆ„ìŠ¤", "salmonella", "listeria", "e.coli", "botulinum"]
            },
            "ont_allergen": {
                "field": "ont_allergen", 
                "values": ["Milk", "Eggs", "Peanuts", "Tree nuts", "Soy", "Wheat", "Fish", "Shellfish"],
                "keywords": ["ìš°ìœ ", "ê³„ë€", "ë•…ì½©", "ê²¬ê³¼ë¥˜", "ì½©", "ë°€", "ìƒì„ ", "ê°‘ê°ë¥˜", "milk", "eggs", "peanuts", "nuts", "soy", "wheat", "fish", "shellfish"]
            },
            "effective_date": {
                "field": "effective_date",
                "values": [],
                "keywords": ["ë‚ ì§œ", "ê¸°ê°„", "ìµœê·¼", "ì´ì „", "í›„", "date", "recent", "before", "after"]
            }
        }
    
    def extract_filter_conditions(self, question: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í•„í„°ë§ ì¡°ê±´ì„ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜ - ë…¼ë¦¬í˜• ì§ˆë¬¸ ì œì™¸"""
        try:
            # ğŸ†• ë¹ ë¥¸ ë…¼ë¦¬í˜• ì§ˆë¬¸ ì²´í¬
            comparison_keywords = ["ë¹„êµ", "compare", "ëŒ€ë¹„", "vs", "ì¤‘ ì–´ëŠ", "ë” ë§ì•„", "ì°¨ì´", "ë…„ê³¼", "ì‘ë…„ê³¼ ì˜¬í•´"]
            question_lower = question.lower()
            
            if any(keyword in question_lower for keyword in comparison_keywords):
                print(f"ğŸ” ë…¼ë¦¬í˜• ì§ˆë¬¸ ê°ì§€ - í•„í„°ë§ ê±´ë„ˆëœ€: {question}")
                return {
                    "filters_detected": False,
                    "conditions": {},
                    "confidence": 0.0,
                    "extraction_method": "logical_question_detected"
                }
            
            # ê¸°ì¡´ LLM ë° íŒ¨í„´ ì¶”ì¶œ ë¡œì§
            llm_result = self._extract_with_llm(question)
            pattern_result = self._extract_with_patterns(question)
            
            final_conditions = self._merge_extraction_results(llm_result, pattern_result)
            
            has_filters = bool(final_conditions.get('conditions'))
            
            print(f"ğŸ” í•„í„° ì¡°ê±´ ì¶”ì¶œ ê²°ê³¼: {has_filters} - {final_conditions.get('conditions', {})}")
            
            return {
                "filters_detected": has_filters,
                "conditions": final_conditions.get('conditions', {}),
                "confidence": final_conditions.get('confidence', 0.5),
                "extraction_method": final_conditions.get('method', 'hybrid')
            }
            
        except Exception as e:
            print(f"âš ï¸ í•„í„° ì¡°ê±´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {
                "filters_detected": False,
                "conditions": {},
                "confidence": 0.0,
                "extraction_method": "error"
            }
    
    def _extract_with_llm(self, question: str) -> Dict[str, Any]:
        """LLMì„ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ í•„í„° ì¡°ê±´ ì¶”ì¶œ - ë³µí•© ì¡°ê±´ ì§€ì›"""
        try:
            metadata_info = self._generate_metadata_guide()
            
            prompt = f"""
    ë‹¤ìŒ ë¦¬ì½œ ê´€ë ¨ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ChromaDB ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¡°ê±´ì„ JSON í˜•íƒœë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
    ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.

    ì§ˆë¬¸: "{question}"

    ğŸš¨ ì§ˆë¬¸ ë¶„ë¥˜ ê·œì¹™:
    1. **í•„í„°ë§ ì§ˆë¬¸ (is_filtering: true)**:
    - "í•´ì‚°ë¬¼ ë¦¬ì½œë§Œ", "í´ë˜ìŠ¤ Ië§Œ", "ì‚´ëª¨ë„¬ë¼ ê´€ë ¨ë§Œ"
    - "A ì¤‘ì—ì„œ Bì¸ ì‚¬ë¡€", "Aì—ì„œ B ë˜ëŠ” Cê°€ ì›ì¸"
    - íŠ¹ì • ì¡°ê±´ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê±¸ëŸ¬ë‚´ëŠ” ì§ˆë¬¸

    2. **ë…¼ë¦¬í˜• ì§ˆë¬¸ (is_filtering: false)**:
    - "Aì™€ B ë¹„êµ", "A ëŒ€ë¹„ B", "ì–´ëŠ ìª½ì´ ë”"
    - "Aì´ë©´ì„œ Bê°€ ì•„ë‹Œ", "Aë¥¼ ì œì™¸í•œ B"

    3. **ìˆ˜ì¹˜í˜• ì§ˆë¬¸ (is_filtering: false)**:
    - "ëª‡ ê±´", "ìƒìœ„ Nê°œ", "ê°€ì¥ ë§ì€"

    ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° í•„ë“œì™€ ê°’:
    {metadata_info}

    ğŸ” ì¶”ì¶œ ì˜ˆì‹œ:
    - "í•´ì‚°ë¬¼ ë¦¬ì½œ ì¤‘ ì‚´ëª¨ë„¬ë¼ ì›ì¸" â†’ {{"ont_food_type": "Seafood Products", "ont_contaminant": "Salmonella"}}
    - "í´ë˜ìŠ¤ I ìœ ì œí’ˆ ë¦¬ì½œ" â†’ {{"class": "I", "ont_food_type": "Dairy Products"}}
    - "ì‚´ëª¨ë„¬ë¼ ë˜ëŠ” ë¦¬ìŠ¤í…Œë¦¬ì•„" â†’ {{"ont_contaminant": ["Salmonella", "Listeria"]}} (OR ì¡°ê±´)

    ì¶œë ¥ í˜•ì‹:
    {{
    "is_filtering": true/false,
    "conditions": {{
        "ont_food_type": "Seafood Products",
        "ont_contaminant": ["Salmonella", "Listeria"]
    }},
    "confidence": 0.9,
    "reasoning": "í•´ì‚°ë¬¼ê³¼ íŠ¹ì • ì„¸ê· (ì‚´ëª¨ë„¬ë¼, ë¦¬ìŠ¤í…Œë¦¬ì•„) ì¡°ê±´ì´ ëª…í™•íˆ ì–¸ê¸‰ë¨"
    }}

    JSON ê²°ê³¼:"""

            response = self.llm.invoke([HumanMessage(content=prompt)])
            result_text = response.content.strip()
            
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].strip()
            
            llm_result = json.loads(result_text)
            
            # is_filteringì´ falseë©´ ì¡°ê±´ ë¹„ìš°ê¸°
            if not llm_result.get('is_filtering', True):
                llm_result['conditions'] = {}
                llm_result['confidence'] = 0.0
            
            llm_result['method'] = 'llm'
            
            print(f"ğŸ§  LLM ì¶”ì¶œ ê²°ê³¼: {llm_result.get('conditions', {})} (í•„í„°ë§ì—¬ë¶€: {llm_result.get('is_filtering', True)})")
            return llm_result
            
        except Exception as e:
            print(f"âš ï¸ LLM ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"conditions": {}, "confidence": 0.0, "method": "llm_failed"}
        
    def _extract_with_patterns(self, question: str) -> Dict[str, Any]:
        """íŒ¨í„´ ê¸°ë°˜ ë°±ì—… í•„í„° ì¡°ê±´ ì¶”ì¶œ - ë³µí•© ì¡°ê±´ ì§€ì›"""
        conditions = {}
        confidence_score = 0.0
        
        question_lower = question.lower()
        
        # ğŸ†• ë³µí•© ì¡°ê±´ ì²˜ë¦¬
        # í•´ì‚°ë¬¼ ê´€ë ¨
        if any(word in question_lower for word in ["í•´ì‚°ë¬¼", "ìˆ˜ì‚°ë¬¼", "seafood", "ìƒì„ ", "ìƒˆìš°", "ê²Œ"]):
            conditions["ont_food_type"] = "Seafood Products"
            confidence_score += 0.3
        
        # ìœ¡ë¥˜ ê´€ë ¨  
        if any(word in question_lower for word in ["ìœ¡ë¥˜", "ê³ ê¸°", "beef", "pork", "chicken", "meat"]):
            conditions["ont_food_type"] = "Livestock Products"
            confidence_score += 0.3
        
        # ìœ ì œí’ˆ ê´€ë ¨
        if any(word in question_lower for word in ["ìœ ì œí’ˆ", "ìš°ìœ ", "ì¹˜ì¦ˆ", "dairy", "milk", "cheese"]):
            conditions["ont_food_type"] = "Dairy Products"
            confidence_score += 0.3
        
        # ğŸ†• ì„¸ê·  ê´€ë ¨ - OR ì¡°ê±´ ì²˜ë¦¬
        bacteria_found = []
        if any(word in question_lower for word in ["ì‚´ëª¨ë„¬ë¼", "salmonella"]):
            bacteria_found.append("Salmonella")
        if any(word in question_lower for word in ["ë¦¬ìŠ¤í…Œë¦¬ì•„", "listeria"]):
            bacteria_found.append("Listeria")
        if any(word in question_lower for word in ["ëŒ€ì¥ê· ", "e.coli", "ecoli"]):
            bacteria_found.append("E.coli")
        
        if bacteria_found:
            if len(bacteria_found) == 1:
                conditions["ont_contaminant"] = bacteria_found[0]
            else:
                conditions["ont_contaminant"] = bacteria_found  # ë³µìˆ˜ ì¡°ê±´
            confidence_score += 0.4
        
        # í´ë˜ìŠ¤ ê´€ë ¨
        class_match = re.search(r'(?:class|í´ë˜ìŠ¤|ë“±ê¸‰)\s*([I1-3])', question_lower)
        if class_match:
            class_num = class_match.group(1)
            if class_num in ['1', 'I']:
                conditions["class"] = "I"
            elif class_num in ['2', 'II']:
                conditions["class"] = "II"
            elif class_num in ['3', 'III']:
                conditions["class"] = "III"
            confidence_score += 0.3
        
        print(f"ğŸ”§ íŒ¨í„´ ì¶”ì¶œ ê²°ê³¼: {conditions}")
        
        return {
            "conditions": conditions,
            "confidence": min(confidence_score, 1.0),
            "method": "pattern"
        }
    
    def _merge_extraction_results(self, llm_result: Dict, pattern_result: Dict) -> Dict[str, Any]:
        """LLM ê²°ê³¼ì™€ íŒ¨í„´ ê²°ê³¼ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ í†µí•©"""
        llm_conditions = llm_result.get('conditions', {})
        pattern_conditions = pattern_result.get('conditions', {})
        
        llm_confidence = llm_result.get('confidence', 0.0)
        pattern_confidence = pattern_result.get('confidence', 0.0)
        
        # LLM ê²°ê³¼ë¥¼ ìš°ì„ ì‹œí•˜ë˜, íŒ¨í„´ ê²°ê³¼ë¡œ ë³´ì™„
        merged_conditions = llm_conditions.copy()
        
        # íŒ¨í„´ì—ì„œë§Œ ë°œê²¬ëœ ì¡°ê±´ ì¶”ê°€ (LLMì—ì„œ ëˆ„ë½ëœ ê²½ìš°)
        for field, value in pattern_conditions.items():
            if field not in merged_conditions:
                merged_conditions[field] = value
        
        # ì‹ ë¢°ë„ëŠ” ë” ë†’ì€ ìª½ + ë³´ë„ˆìŠ¤
        final_confidence = max(llm_confidence, pattern_confidence)
        if llm_conditions and pattern_conditions:
            final_confidence = min(final_confidence + 0.1, 1.0)  # ë‘ ë°©ë²• ëª¨ë‘ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤
        
        return {
            "conditions": merged_conditions,
            "confidence": final_confidence,
            "method": "hybrid"
        }
    
    def _generate_metadata_guide(self) -> str:
        """LLMì—ê²Œ ì œê³µí•  ë©”íƒ€ë°ì´í„° í•„ë“œ ê°€ì´ë“œ ìƒì„±"""
        guide_lines = []
        
        for field_key, field_info in self.field_mappings.items():
            field_name = field_info["field"]
            values = field_info["values"]
            keywords = field_info["keywords"]
            
            if values:
                value_list = ", ".join(values[:5])  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                guide_lines.append(f"- {field_name}: {value_list} (í‚¤ì›Œë“œ: {', '.join(keywords[:3])})")
            else:
                guide_lines.append(f"- {field_name}: ë‚ ì§œ í˜•ì‹ (í‚¤ì›Œë“œ: {', '.join(keywords[:3])})")
        
        return "\n".join(guide_lines)
    
    def is_filtering_question(self, question: str) -> bool:
        """ì§ˆë¬¸ì´ í•„í„°ë§ ì§ˆë¬¸ì¸ì§€ ë¹ ë¥´ê²Œ íŒë‹¨"""
        result = self.extract_filter_conditions(question)
        return result.get('filters_detected', False) and result.get('confidence', 0) > 0.6
    
    def convert_to_chroma_filter(self, conditions: Dict[str, Any]) -> Dict[str, Any]:
        """ì¶”ì¶œëœ ì¡°ê±´ì„ ChromaDB í•„í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜ - OR ì¡°ê±´ ì§€ì›"""
        if not conditions:
            return {}
        
        chroma_filter = {}
        
        for field, value in conditions.items():
            if value and str(value).strip():
                if isinstance(value, list):
                    # OR ì¡°ê±´ - ChromaDBì˜ $in ì—°ì‚°ì ì‚¬ìš©
                    chroma_filter[field] = {"$in": value}
                else:
                    chroma_filter[field] = value
        
        print(f"ğŸ”§ ChromaDB í•„í„° ë³€í™˜: {chroma_filter}")
        return chroma_filter