# utils/processors/logical_processor.py - ê°œì„ ëœ ë²„ì „

import json
import re
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple
from collections import Counter, defaultdict
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

class LogicalQueryProcessor:
    """LLM ê¸°ë°˜ ë…¼ë¦¬ ì—°ì‚°(ì œì™¸, ë¹„êµ, ì¡°ê±´ë¶€) ì§ˆë¬¸ ì²˜ë¦¬ í´ë˜ìŠ¤ - ê°œì„ ëœ ë²„ì „"""
    
    def __init__(self, vectorstore):
        self.vectorstore = vectorstore
        self.llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
        self.filter_cache = {}
        self.exclude_cache = {}
        self.metadata_sample = None
        # ğŸ†• í˜„ì¬ ë‚ ì§œ ì •ë³´ ì¶”ê°€
        self.current_date = datetime.now()
        self.current_year = self.current_date.year
    
    def _resolve_relative_time(self, time_expression: str) -> str:
        """ìƒëŒ€ì  ì‹œê°„ í‘œí˜„ì„ ì ˆëŒ€ ì—°ë„ë¡œ ë³€í™˜"""
        time_lower = time_expression.lower().strip()
        
        # ìƒëŒ€ì  ì‹œê°„ ë§¤í•‘
        if time_lower in ['ì˜¬í•´', 'ì´ë²ˆë…„', 'ì´ë²ˆ ë…„', 'í˜„ì¬ë…„', '2025ë…„']:
            return str(self.current_year)  # 2025
        elif time_lower in ['ì‘ë…„', 'ì§€ë‚œí•´', 'ì§€ë‚œ í•´', 'ì‘ë…„ë„']:
            return str(self.current_year - 1)  # 2024
        elif time_lower in ['ì¬ì‘ë…„', 'ì¬ì‘ë…„ë„']:
            return str(self.current_year - 2)  # 2023
        
        # ì ˆëŒ€ ì—°ë„ ì¶”ì¶œ
        year_match = re.search(r'(\d{4})', time_expression)
        if year_match:
            return year_match.group(1)
        
        # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        return time_expression
    
    def analyze_logical_intent(self, question: str) -> Dict[str, Any]:
        """LLMì„ í™œìš©í•œ ë…¼ë¦¬ ì—°ì‚° ì˜ë„ ë¶„ì„ - í˜„ì¬ ë‚ ì§œ ì •ë³´ í¬í•¨"""
        
        # ğŸ†• í˜„ì¬ ë‚ ì§œ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        current_date_str = self.current_date.strftime("%Yë…„ %mì›” %dì¼")
        
        prompt = f"""
ì˜¤ëŠ˜ ë‚ ì§œ: {current_date_str} (ë”°ë¼ì„œ ì˜¬í•´={self.current_year}ë…„, ì‘ë…„={self.current_year-1}ë…„)

ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”. ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.

ì§ˆë¬¸: "{question}"

ë¶„ì„ ê¸°ì¤€:
1. query_type:
   - "logical": ë…¼ë¦¬ ì—°ì‚°ì´ í•„ìš”í•œ ì§ˆë¬¸ (ì œì™¸, ë¹„êµ, ì¡°ê±´ë¶€ ë“±)
   - "semantic": ì¼ë°˜ì ì¸ ê²€ìƒ‰ ì§ˆë¬¸
   - "numerical": ê°œìˆ˜, ìˆœìœ„ ë“± ìˆ˜ì¹˜í˜• ì§ˆë¬¸

2. operation (logicalì¸ ê²½ìš°ë§Œ):
   - "exclude": íŠ¹ì • ì¡°ê±´ì„ ì œì™¸ ("~ë¥¼ ì œì™¸í•œ", "~ë¹¼ê³ ", "~ì™¸ì—")
   - "compare": ë‘ ëŒ€ìƒì˜ ë¹„êµ ("~ì™€ ë¹„êµ", "~ëŒ€ë¹„", "ì°¨ì´ì ", "ê°„ ë¹„êµ", "ì¤‘ ì–´ëŠ ìª½", "ë” ë§ì•„")
   - "temporal": ì‹œê°„ë³„ ë¹„êµ ("ì‘ë…„ê³¼ ì˜¬í•´", "ì›”ë³„", "ê¸°ê°„ë³„", "ë…„ë„ë³„", "ì›ì¸ ë¹„êµ")
   - "conditional": ë³µí•© ì¡°ê±´ ("~ì´ë©´ì„œ ~ì´ ì•„ë‹Œ", "~ì¸ ê²½ìš°ì—ë§Œ", "~ì¼ ë•Œ")

3. main_subjects: ì£¼ìš” ë¶„ì„ ëŒ€ìƒë“¤ (ë°°ì—´)
4. exclude_conditions: ì œì™¸í•  ì¡°ê±´ë“¤ (ë°°ì—´) 
5. conditional_filters: ë³µí•© ì¡°ê±´ë“¤ (ë°°ì—´)
6. time_periods: ì‹œê°„ ê¸°ê°„ë“¤ (ë°°ì—´) - ìƒëŒ€ì  í‘œí˜„ë„ í¬í•¨
7. confidence: ë¶„ì„ í™•ì‹ ë„ (0.0-1.0)

ì¤‘ìš”í•œ ì‹œê°„ ë§¤í•‘:
- "ì˜¬í•´" â†’ {self.current_year}ë…„
- "ì‘ë…„" â†’ {self.current_year-1}ë…„
- "ì¬ì‘ë…„" â†’ {self.current_year-2}ë…„

ì˜ˆì‹œ:
- "ì‘ë…„ê³¼ ì˜¬í•´ì˜ ë¦¬ì½œ ì›ì¸ì— ëŒ€í•´ì„œ ë¹„êµí•´ì¤˜"
  â†’ {{"query_type": "logical", "operation": "temporal", "time_periods": ["ì‘ë…„", "ì˜¬í•´"], "main_subjects": ["ë¦¬ì½œ ì›ì¸"], "confidence": 0.95}}

JSON ê²°ê³¼:"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result_text = response.content.strip()
            
            # JSON ì¶”ì¶œ
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].strip()
            
            intent = json.loads(result_text)
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            intent.setdefault('query_type', 'semantic')
            intent.setdefault('confidence', 0.5)
            intent.setdefault('main_subjects', [])
            intent.setdefault('exclude_conditions', [])
            intent.setdefault('conditional_filters', [])
            intent.setdefault('time_periods', [])
            
            print(f"ğŸ§  ë…¼ë¦¬ ì—°ì‚° ì˜ë„ ë¶„ì„: {intent}")
            return intent
            
        except Exception as e:
            print(f"âš ï¸ ë…¼ë¦¬ ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'query_type': 'semantic',
                'confidence': 0.5,
                'main_subjects': [],
                'exclude_conditions': [],
                'conditional_filters': [],
                'time_periods': []
            }
    
    def _filter_by_llm_understanding(self, metadatas: List[Dict], documents: List[str], filter_description: str) -> List[Tuple[Dict, str]]:
        """LLMì´ ë©”íƒ€ë°ì´í„°ë¥¼ ì§ì ‘ ì´í•´í•´ì„œ í•„í„°ë§ - í˜„ì¬ ë‚ ì§œ ì •ë³´ í¬í•¨"""
        
        cache_key = filter_description.lower().strip()
        if cache_key in self.filter_cache:
            filter_logic = self.filter_cache[cache_key]
            print(f"ğŸ”„ ìºì‹œëœ í•„í„°ë§ ë¡œì§ ì‚¬ìš©: {filter_description}")
        else:
            sample_metadata = self._get_metadata_sample()
            actual_values = self._get_actual_metadata_values(metadatas[:50])
            
            # ğŸ†• í˜„ì¬ ë‚ ì§œ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            current_date_str = self.current_date.strftime("%Yë…„ %mì›” %dì¼")
            
            prompt = f"""
ì˜¤ëŠ˜ ë‚ ì§œ: {current_date_str} (ì˜¬í•´={self.current_year}ë…„, ì‘ë…„={self.current_year-1}ë…„)

ë‹¹ì‹ ì€ FDA ë¦¬ì½œ ë°ì´í„° í•„í„°ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ ì°¾ê¸° ìœ„í•œ í•„í„°ë§ ë¡œì§ì„ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

í•„í„°ë§ ì¡°ê±´: "{filter_description}"

ë©”íƒ€ë°ì´í„° êµ¬ì¡° ì˜ˆì‹œ:
{json.dumps(sample_metadata, indent=2)}

ì‹¤ì œ ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ëŠ” ê°’ë“¤:
{json.dumps(actual_values, indent=2)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "filter_logic": [
        {{
            "field": "ë©”íƒ€ë°ì´í„° í•„ë“œëª…",
            "condition": "contains|equals|exists|not_exists|starts_with",
            "value": "ì°¾ì„ ê°’ (exists/not_existsë©´ null)",
            "reasoning": "ì´ ì¡°ê±´ì„ ì„¤ì •í•œ ì´ìœ "
        }}
    ],
    "combination": "AND|OR"
}}

ì¤‘ìš”í•œ ë§¤í•‘ ê·œì¹™ (í˜„ì¬ ë‚ ì§œ ê¸°ì¤€):
- "ì˜¬í•´" â†’ effective_dateê°€ "{self.current_year}"ë¡œ ì‹œì‘
- "ì‘ë…„" â†’ effective_dateê°€ "{self.current_year-1}"ë¡œ ì‹œì‘  
- "ì¬ì‘ë…„" â†’ effective_dateê°€ "{self.current_year-2}"ë¡œ ì‹œì‘
- "ìœ¡ë¥˜" â†’ ont_food_typeì—ì„œ "Livestock Products" ì°¾ê¸°
- "ìœ ì œí’ˆ" â†’ ont_food_typeì—ì„œ "Dairy Products" ì°¾ê¸°
- "í•´ì‚°ë¬¼" â†’ ont_food_typeì—ì„œ "Seafood Products" ì°¾ê¸°
- "ì•Œë ˆë¥´ê¸° ê´€ë ¨" â†’ ont_allergen í•„ë“œì— ê°’ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸

ì‹¤ì œ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•œ ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš”.

JSONë§Œ ë°˜í™˜:"""

            try:
                response = self.llm.invoke([HumanMessage(content=prompt)])
                result_text = response.content.strip()
                
                if "```json" in result_text:
                    result_text = result_text.split("```json")[1].split("```")[0].strip()
                elif "```" in result_text:
                    result_text = result_text.split("```")[1].strip()
                
                filter_logic = json.loads(result_text)
                self.filter_cache[cache_key] = filter_logic
                print(f"ğŸ†• ìƒˆ í•„í„°ë§ ë¡œì§ ìƒì„±: {filter_description}")
                print(f"ğŸ“‹ ìƒì„±ëœ ë¡œì§: {filter_logic}")
                
            except Exception as e:
                print(f"âš ï¸ LLM í•„í„°ë§ ë¡œì§ ìƒì„± ì‹¤íŒ¨: {e}")
                return []
        
        return self._apply_llm_filter_logic(metadatas, documents, filter_logic)
    
    def _handle_conditional_query_llm(self, intent: Dict, metadatas: List[Dict], documents: List[str]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì¡°ê±´ë¶€ ì²˜ë¦¬ - ë³µí•© ì¡°ê±´ ê°œì„ """
        conditional_filters = intent.get('conditional_filters', [])
        main_subjects = intent.get('main_subjects', [])
        
        # conditional_filtersê°€ ì—†ìœ¼ë©´ main_subjects ì‚¬ìš©
        if not conditional_filters and main_subjects:
            conditional_filters = main_subjects
        
        if not conditional_filters:
            return {'error': 'ì¡°ê±´ë¶€ í•„í„°ë§í•  ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.'}
        
        print(f"ğŸ” LLM ì¡°ê±´ë¶€ í•„í„°ë§: {conditional_filters}")
        
        # ğŸ†• ë³µí•© ì¡°ê±´ íŒŒì‹± ("ìœ ì œí’ˆì´ë©´ì„œ ì•Œë ˆë¥´ê¸° ê´€ë ¨ì´ ì•„ë‹Œ")
        positive_conditions = []
        negative_conditions = []
        
        for condition in conditional_filters:
            if 'ì•„ë‹Œ' in condition or 'ì—†ëŠ”' in condition or 'ì œì™¸' in condition:
                # ë¶€ì • ì¡°ê±´
                clean_condition = condition.replace('ì´ ì•„ë‹Œ', '').replace('ê°€ ì•„ë‹Œ', '').replace('ê´€ë ¨ì´ ì•„ë‹Œ', 'ê´€ë ¨').replace('ì œì™¸', '').strip()
                negative_conditions.append(clean_condition)
            else:
                # ê¸ì • ì¡°ê±´
                positive_conditions.append(condition)
        
        print(f"âœ… ê¸ì • ì¡°ê±´: {positive_conditions}")
        print(f"âŒ ë¶€ì • ì¡°ê±´: {negative_conditions}")
        
        # 1ë‹¨ê³„: ê¸ì • ì¡°ê±´ í•„í„°ë§
        if positive_conditions:
            positive_description = ', '.join(positive_conditions)
            filtered_data = self._filter_by_llm_understanding(metadatas, documents, positive_description)
        else:
            filtered_data = list(zip(metadatas, documents))
        
        print(f"1ë‹¨ê³„ ê¸ì • ì¡°ê±´ í•„í„°ë§ í›„: {len(filtered_data)}ê±´")
        
        # 2ë‹¨ê³„: ë¶€ì • ì¡°ê±´ ì œì™¸
        if negative_conditions:
            final_data = []
            excluded_data = []
            
            for metadata, doc in filtered_data:
                should_exclude = False
                for neg_condition in negative_conditions:
                    if self._matches_negative_condition(metadata, neg_condition):
                        should_exclude = True
                        break
                
                if should_exclude:
                    excluded_data.append((metadata, doc))
                else:
                    final_data.append((metadata, doc))
            
            print(f"2ë‹¨ê³„ ë¶€ì • ì¡°ê±´ ì œì™¸ í›„: {len(final_data)}ê±´ (ì œì™¸: {len(excluded_data)}ê±´)")
        else:
            final_data = filtered_data
            excluded_data = []
        
        # ê²°ê³¼ ë¶„ì„
        condition_analysis = {}
        example_links = []
        
        # ë¦¬ì½œ ì›ì¸ë³„ ë¶„ì„
        reasons = []
        allergens = []
        contaminants = []
        food_types = []
        
        for metadata, doc in final_data:
            food_type = metadata.get('ont_food_type', 'ê¸°íƒ€')
            reason = metadata.get('ont_recall_reason', 'ê¸°íƒ€')
            allergen = metadata.get('ont_allergen', '')
            contaminant = metadata.get('ont_contaminant', '')
            
            reasons.append(reason)
            food_types.append(food_type)
            if allergen and allergen.lower() not in ['null', 'none', '']:
                allergens.append(allergen)
            if contaminant and contaminant.lower() not in ['null', 'none', '']:
                contaminants.append(contaminant)
            
            if food_type not in condition_analysis:
                condition_analysis[food_type] = {
                    'count': 0,
                    'reasons': []
                }
            
            condition_analysis[food_type]['count'] += 1
            condition_analysis[food_type]['reasons'].append(reason)
        
        # ì˜ˆì‹œ ë§í¬ ìƒì„±
        for metadata, doc in final_data[:5]:
            url = metadata.get('url', '')
            title = metadata.get('title', '')
            date = metadata.get('effective_date', '')
            if url and title:
                short_title = title[:50] + "..." if len(title) > 50 else title
                example_links.append(f"â€¢ {short_title} ({date})\n  {url}")
        
        # ì¡°ê±´ë³„ ìƒìœ„ ì´ìœ  ì •ë¦¬
        for food_type in condition_analysis:
            reasons_list = condition_analysis[food_type]['reasons']
            condition_analysis[food_type]['top_reasons'] = dict(Counter(reasons_list).most_common(3))
            del condition_analysis[food_type]['reasons']
        
        # ì „ì²´ í†µê³„
        reason_counts = Counter(reasons)
        allergen_counts = Counter(allergens)
        contaminant_counts = Counter(contaminants)
        food_type_counts = Counter(food_types)
        
        return {
            'type': 'conditional',
            'operation': 'conditional',
            'result': {
                'total_count': len(final_data),
                'excluded_count': len(excluded_data),
                'condition_analysis': condition_analysis,
                'positive_conditions': positive_conditions,
                'negative_conditions': negative_conditions,
                'top_reasons': dict(reason_counts.most_common(5)),
                'top_allergens': dict(allergen_counts.most_common(3)),
                'top_contaminants': dict(contaminant_counts.most_common(3)),
                'top_food_types': dict(food_type_counts.most_common(3))
            },
            'description': f"{', '.join(conditional_filters)} ì¡°ê±´ì— ë§ëŠ” {len(final_data)}ê±´ì˜ ë¦¬ì½œ ì‚¬ë¡€",
            'example_links': example_links,
            'intent': intent
        }

    def _matches_negative_condition(self, metadata: Dict, condition: str) -> bool:
        """ë¶€ì • ì¡°ê±´ ë§¤ì¹­ í™•ì¸"""
        condition_lower = condition.lower()
        
        # ì•Œë ˆë¥´ê¸° ê´€ë ¨ ì²´í¬
        if 'ì•Œë ˆë¥´ê¸°' in condition_lower:
            allergen_value = metadata.get('ont_allergen')
            return allergen_value is not None and str(allergen_value).lower() not in ['null', 'none', '']
        
        # ê¸°íƒ€ ì¡°ê±´ë“¤ì€ ì¼ë°˜ ë§¤ì¹­
        searchable_fields = [
            'ont_contaminant', 'ont_allergen', 'ont_recall_reason',
            'ont_food', 'ont_food_type', 'title'
        ]
        
        for field in searchable_fields:
            field_value = str(metadata.get(field, '')).lower()
            if condition_lower in field_value:
                return True
        
        return False

    def _handle_exclude_query_llm(self, intent: Dict, metadatas: List[Dict], documents: List[str]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì œì™¸ ì—°ì‚° ì²˜ë¦¬"""
        main_subjects = intent.get('main_subjects', [])
        exclude_conditions = intent.get('exclude_conditions', [])
        
        print(f"ğŸ” LLM ì œì™¸ ì—°ì‚°: {main_subjects}ì—ì„œ {exclude_conditions} ì œì™¸")
        
        # 1ë‹¨ê³„: ì£¼ ëŒ€ìƒ í•„í„°ë§
        if main_subjects:
            main_description = ', '.join(main_subjects)
            filtered_data = self._filter_by_llm_understanding(metadatas, documents, main_description)
        else:
            filtered_data = list(zip(metadatas, documents))
        
        print(f"1ë‹¨ê³„ í•„í„°ë§ í›„: {len(filtered_data)}ê±´")
        
        # 2ë‹¨ê³„: ì œì™¸ ì¡°ê±´ ì ìš©
        if exclude_conditions:
            final_data = []
            excluded_data = []
            
            print(f"ğŸš« ì œì™¸ ì¡°ê±´ ì ìš© ì¤‘: {exclude_conditions}")
            
            for metadata, doc in filtered_data:
                if self._llm_should_exclude(metadata, exclude_conditions):
                    excluded_data.append((metadata, doc))
                else:
                    final_data.append((metadata, doc))
            
            print(f"âœ… ì œì™¸ ì²˜ë¦¬ ì™„ë£Œ: ì œì™¸ {len(excluded_data)}ê±´, ìµœì¢… {len(final_data)}ê±´")
            
        else:
            final_data = filtered_data
            excluded_data = []
        
        return self._format_exclude_results(filtered_data, final_data, excluded_data, intent)

    def _llm_should_exclude(self, metadata: Dict, exclude_conditions: List[str]) -> bool:
        """LLMì´ ê°œë³„ ë¬¸ì„œì˜ ì œì™¸ ì—¬ë¶€ íŒë‹¨"""
        
        # ìºì‹±ì„ ìœ„í•œ í‚¤ ìƒì„±
        cache_key = f"{metadata.get('url', '')}-{'-'.join(exclude_conditions)}"
        if cache_key in self.exclude_cache:
            return self.exclude_cache[cache_key]
        
        prompt = f"""
    ë‹¤ìŒ ë¦¬ì½œ ë°ì´í„°ê°€ ì œì™¸ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

    ì œì™¸ ì¡°ê±´: {', '.join(exclude_conditions)}

    ë¦¬ì½œ ë°ì´í„°:
    - ì‹í’ˆ ì¢…ë¥˜: {metadata.get('ont_food_type', 'N/A')}
    - ì‹í’ˆëª…: {metadata.get('ont_food', 'N/A')}
    - ë¦¬ì½œ ì‚¬ìœ : {metadata.get('ont_recall_reason', 'N/A')}
    - ì•Œë ˆë¥´ê¸° ìš”ì†Œ: {metadata.get('ont_allergen', 'N/A')}
    - ì˜¤ì—¼ ë¬¼ì§ˆ: {metadata.get('ont_contaminant', 'N/A')}
    - ì œëª©: {metadata.get('title', 'N/A')[:100]}

    ì´ ë°ì´í„°ê°€ ì œì™¸ ì¡°ê±´ì— í•´ë‹¹í•˜ë©´ "YES", ì•„ë‹ˆë©´ "NO"ë¡œë§Œ ë‹µí•˜ì„¸ìš”.

    í˜•ì‹: YES ë˜ëŠ” NO"""
        
        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result = response.content.strip().upper()
            
            should_exclude = result.startswith('YES')
            self.exclude_cache[cache_key] = should_exclude
            
            return should_exclude
            
        except Exception as e:
            print(f"âš ï¸ LLM ì œì™¸ íŒë‹¨ ì‹¤íŒ¨: {e}")
            return False

    def _format_exclude_results(self, original_data: List, final_data: List, excluded_data: List, intent: Dict) -> Dict[str, Any]:
        """ì œì™¸ ì—°ì‚° ê²°ê³¼ í¬ë§·íŒ…"""
        excluded_count = len(excluded_data)
        
        # ì œì™¸ëœ ì‚¬ë¡€ì˜ ì£¼ìš” ì›ì¸ ë¶„ì„
        excluded_reasons = []
        for metadata, doc in excluded_data:
            reason = metadata.get('ont_recall_reason', 'ê¸°íƒ€')
            allergen = metadata.get('ont_allergen', '')
            if allergen:
                reason += f" ({allergen})"
            excluded_reasons.append(reason)
        
        excluded_reason_counts = Counter(excluded_reasons)
        
        # ìµœì¢… ê²°ê³¼ì˜ ì£¼ìš” ì›ì¸ ë¶„ì„
        final_reasons = []
        example_links = []
        for metadata, doc in final_data[:5]:
            reason = metadata.get('ont_recall_reason', 'ê¸°íƒ€')
            contaminant = metadata.get('ont_contaminant', '')
            if contaminant:
                reason += f" ({contaminant})"
            final_reasons.append(reason)
            
            # ì˜ˆì‹œ ë§í¬ ì¶”ê°€
            url = metadata.get('url', '')
            title = metadata.get('title', '')
            date = metadata.get('effective_date', '')
            if url and title:
                short_title = title[:50] + "..." if len(title) > 50 else title
                example_links.append(f"â€¢ {short_title} ({date})\n  {url}")
        
        final_reason_counts = Counter(final_reasons)
        
        main_subjects = intent.get('main_subjects', [])
        exclude_conditions = intent.get('exclude_conditions', [])
        
        return {
            'type': 'exclude',
            'operation': 'exclude',
            'result': {
                'total_before': len(original_data),
                'excluded_count': excluded_count,
                'final_count': len(final_data),
                'excluded_reasons': dict(excluded_reason_counts.most_common(5)),
                'final_reasons': dict(final_reason_counts.most_common(5))
            },
            'description': f"{', '.join(main_subjects)} ì¤‘ {', '.join(exclude_conditions)}ë¥¼ ì œì™¸í•œ {len(final_data)}ê±´ì˜ ë¦¬ì½œ ì‚¬ë¡€",
            'example_links': example_links,
            'intent': intent
        }

    
    def _handle_compare_query_llm(self, intent: Dict, metadatas: List[Dict], documents: List[str]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ë¹„êµ ì—°ì‚° ì²˜ë¦¬ - ì›ì¸ ë¶„ì„ ê°•í™”"""
        subjects = intent.get('main_subjects', [])
        time_periods = intent.get('time_periods', [])
        
        # ì‹œê°„ ë¹„êµì¸ ê²½ìš°
        if time_periods and len(time_periods) >= 2:
            # ğŸ†• ìƒëŒ€ì  ì‹œê°„ì„ ì ˆëŒ€ ì—°ë„ë¡œ ë³€í™˜
            resolved_periods = []
            for period in time_periods:
                resolved_year = self._resolve_relative_time(period)
                resolved_periods.append(resolved_year)
            
            subjects = resolved_periods
            is_temporal = True
            print(f"ğŸ• ì‹œê°„ ë§¤í•‘: {time_periods} â†’ {resolved_periods}")
        else:
            is_temporal = False
        
        if len(subjects) < 2:
            return {'error': 'ë¹„êµí•  ëŒ€ìƒì´ 2ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.'}
        
        print(f"ğŸ” LLM {'ì‹œê°„' if is_temporal else 'ì¼ë°˜'} ë¹„êµ ì—°ì‚°: {subjects} ê°„ ë¹„êµ")
        
        comparison_results = {}
        example_links = {}
        
        for subject in subjects:
            if is_temporal:
                # ğŸ†• ì—°ë„ ê¸°ë°˜ í•„í„°ë§
                filtered_data = []
                year = subject  # ì´ë¯¸ resolvedëœ ì—°ë„
                for metadata, doc in zip(metadatas, documents):
                    effective_date = metadata.get('effective_date', '')
                    if effective_date.startswith(year):
                        filtered_data.append((metadata, doc))
            else:
                filtered_data = self._filter_by_llm_understanding(metadatas, documents, subject)
            
            print(f"ğŸ“Š {subject}: {len(filtered_data)}ê±´ ë°ì´í„°")
            
            # ğŸ†• ë¦¬ì½œ ì›ì¸ ìƒì„¸ ë¶„ì„
            reasons = []
            allergens = []
            contaminants = []
            food_types = []
            links = []
            monthly_counts = defaultdict(int)
            
            for metadata, doc in filtered_data:
                # ë‹¤ì–‘í•œ ì›ì¸ ì •ë³´ ìˆ˜ì§‘
                reason = metadata.get('ont_recall_reason', 'ê¸°íƒ€')
                allergen = metadata.get('ont_allergen', '')
                contaminant = metadata.get('ont_contaminant', '')
                food_type = metadata.get('ont_food_type', 'ê¸°íƒ€')
                
                reasons.append(reason)
                if allergen and allergen.lower() not in ['null', 'none', '']:
                    allergens.append(allergen)
                if contaminant and contaminant.lower() not in ['null', 'none', '']:
                    contaminants.append(contaminant)
                food_types.append(food_type)
                
                # ì‹œê°„ ë¹„êµìš© ì›”ë³„ ë¶„í¬
                if is_temporal:
                    date_str = metadata.get('effective_date', '')
                    if date_str:
                        try:
                            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                            month_key = date_obj.strftime('%Y-%m')
                            monthly_counts[month_key] += 1
                        except:
                            pass
            
            # ì˜ˆì‹œ ë§í¬ (ìƒìœ„ 3ê°œ)
            for metadata, doc in filtered_data[:3]:
                url = metadata.get('url', '')
                title = metadata.get('title', '')
                date = metadata.get('effective_date', '')
                if url and title:
                    short_title = title[:50] + "..." if len(title) > 50 else title
                    links.append(f"â€¢ {short_title} ({date})\n  {url}")
            
            # ğŸ†• ìƒì„¸ ì›ì¸ ë¶„ì„
            reason_counts = Counter(reasons)
            allergen_counts = Counter(allergens)
            contaminant_counts = Counter(contaminants)
            food_type_counts = Counter(food_types)
            
            result_data = {
                'total_count': len(filtered_data),
                'top_reasons': dict(reason_counts.most_common(5)),  # ìƒìœ„ 5ê°œë¡œ í™•ì¥
                'top_allergens': dict(allergen_counts.most_common(3)),
                'top_contaminants': dict(contaminant_counts.most_common(3)),
                'top_food_types': dict(food_type_counts.most_common(3)),
                'avg_monthly': len(filtered_data) / 12 if len(filtered_data) > 0 else 0
            }
            
            # ì‹œê°„ ë¹„êµì¸ ê²½ìš° ì›”ë³„ ë¶„í¬ ì¶”ê°€
            if is_temporal:
                result_data['monthly_distribution'] = dict(monthly_counts)
            
            comparison_results[subject] = result_data
            example_links[subject] = links
        
        # ğŸ†• ì‹œê°„ ë¹„êµì¸ ê²½ìš° ì›ì¸ë³„ ë³€í™” ë¶„ì„
        cause_analysis = {}
        if is_temporal and len(comparison_results) >= 2:
            periods = list(comparison_results.keys())
            recent_data = comparison_results[periods[-1]]
            previous_data = comparison_results[periods[0]]
            
            # ì „ì²´ ê±´ìˆ˜ ë³€í™”
            recent_count = recent_data['total_count']
            previous_count = previous_data['total_count']
            
            if previous_count > 0:
                change_rate = ((recent_count - previous_count) / previous_count) * 100
                trend = "ì¦ê°€" if change_rate > 10 else "ê°ì†Œ" if change_rate < -10 else "ìœ ì§€"
            else:
                change_rate = 0
                trend = "ë°ì´í„° ë¶€ì¡±"
            
            # ì£¼ìš” ì›ì¸ë³„ ë³€í™” ë¶„ì„
            cause_changes = {}
            recent_reasons = recent_data.get('top_reasons', {})
            previous_reasons = previous_data.get('top_reasons', {})
            
            all_reasons = set(list(recent_reasons.keys()) + list(previous_reasons.keys()))
            for reason in all_reasons:
                recent_cnt = recent_reasons.get(reason, 0)
                previous_cnt = previous_reasons.get(reason, 0)
                
                if previous_cnt > 0:
                    reason_change = ((recent_cnt - previous_cnt) / previous_cnt) * 100
                else:
                    reason_change = 100 if recent_cnt > 0 else 0
                
                cause_changes[reason] = {
                    'previous': previous_cnt,
                    'recent': recent_cnt,
                    'change_rate': round(reason_change, 1)
                }
            
            cause_analysis = {
                'total_change_rate': round(change_rate, 1),
                'trend': trend,
                'cause_changes': cause_changes
            }
        
        result = {
            'type': 'temporal' if is_temporal else 'compare',
            'operation': 'temporal' if is_temporal else 'compare',
            'result': comparison_results,
            'description': f"{', '.join(subjects)} ê°„ ë¦¬ì½œ ì‚¬ë¡€ ë¹„êµ ë¶„ì„ (ì›ì¸ë³„ ìƒì„¸ ë¶„ì„ í¬í•¨)",
            'example_links': example_links,
            'intent': intent
        }
        
        if cause_analysis:
            result['cause_analysis'] = cause_analysis
        
        return result

    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼...
    def _get_metadata_sample(self):
        """ë©”íƒ€ë°ì´í„° êµ¬ì¡° ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸° (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
        if self.metadata_sample is None:
            try:
                collection = self.vectorstore._collection
                sample_data = collection.get(limit=1, include=["metadatas"])
                if sample_data and sample_data.get('metadatas'):
                    self.metadata_sample = sample_data['metadatas'][0]
                else:
                    self.metadata_sample = {}
            except Exception as e:
                print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.metadata_sample = {}
        return self.metadata_sample
    
    def _get_actual_metadata_values(self, metadatas_sample: List[Dict]) -> Dict[str, List[str]]:
        """ì‹¤ì œ ë©”íƒ€ë°ì´í„°ì—ì„œ ê°’ë“¤ ì¶”ì¶œ"""
        values = {}
        key_fields = ['ont_food_type', 'ont_food', 'ont_allergen', 'ont_contaminant', 'ont_recall_reason']
        
        for field in key_fields:
            unique_values = set()
            for metadata in metadatas_sample:
                value = metadata.get(field)
                if value and str(value).lower() not in ['null', 'none', '']:
                    unique_values.add(str(value))
            values[field] = list(unique_values)[:10]
        
        return values
    
    def _apply_llm_filter_logic(self, metadatas: List[Dict], documents: List[str], filter_logic: Dict) -> List[Tuple[Dict, str]]:
        """LLMì´ ìƒì„±í•œ í•„í„°ë§ ë¡œì§ ì ìš©"""
        filtered = []
        combination = filter_logic.get('combination', 'AND')
        
        for metadata, doc in zip(metadatas, documents):
            conditions_met = []
            
            for condition in filter_logic.get('filter_logic', []):
                field = condition['field']
                condition_type = condition['condition']
                value = condition.get('value')
                
                field_value = str(metadata.get(field, '')).lower()
                
                if condition_type == 'contains':
                    met = value.lower() in field_value
                elif condition_type == 'equals':
                    met = field_value == value.lower()
                elif condition_type == 'exists':
                    met = field_value and field_value not in ['null', 'none', '']
                elif condition_type == 'not_exists':
                    met = not field_value or field_value in ['null', 'none', '']
                elif condition_type == 'starts_with':
                    met = field_value.startswith(value.lower())
                else:
                    met = False
                
                conditions_met.append(met)
            
            if combination == 'AND':
                matches = all(conditions_met) if conditions_met else False
            else:
                matches = any(conditions_met) if conditions_met else False
            
            if matches:
                filtered.append((metadata, doc))
        
        return filtered
    
    def is_logical_question(self, question: str) -> bool:
        """ì§ˆë¬¸ì´ ë…¼ë¦¬í˜•ì¸ì§€ LLMìœ¼ë¡œ íŒë‹¨"""
        intent = self.analyze_logical_intent(question)
        return intent.get('query_type') == 'logical' and intent.get('confidence', 0) > 0.6
    
    def process_logical_query(self, question: str) -> Dict[str, Any]:
        """ë…¼ë¦¬í˜• ì§ˆë¬¸ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        try:
            intent = self.analyze_logical_intent(question)
            
            if intent.get('query_type') != 'logical':
                return {'error': 'ë…¼ë¦¬í˜• ì§ˆë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.'}
            
            # ChromaDBì—ì„œ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            print("ğŸ“Š ChromaDBì—ì„œ ì „ì²´ ë©”íƒ€ë°ì´í„° ë¡œë”© ì¤‘...")
            
            try:
                collection = self.vectorstore._collection
                all_data = collection.get(include=["metadatas", "documents"])
                metadatas = all_data.get('metadatas', [])
                documents = all_data.get('documents', [])
                
                print(f"âœ… ì´ {len(metadatas)}ê°œ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„° ë¡œë“œë¨")
                
                if not metadatas:
                    return {'error': 'ChromaDBì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
                
            except Exception as db_error:
                print(f"âŒ ChromaDB ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {db_error}")
                return {'error': f'ChromaDB ì ‘ê·¼ ì˜¤ë¥˜: {str(db_error)}'}
            
            # ì—°ì‚° ìœ í˜•ë³„ ì²˜ë¦¬
            operation = intent.get('operation', 'exclude')
            
            if operation == 'exclude':
                return self._handle_exclude_query_llm(intent, metadatas, documents)
            elif operation == 'compare' or operation == 'temporal':
                return self._handle_compare_query_llm(intent, metadatas, documents)
            elif operation == 'conditional':
                return self._handle_conditional_query_llm(intent, metadatas, documents)
            else:
                return {'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë…¼ë¦¬ ì—°ì‚°: {operation}'}
                
        except Exception as e:
            print(f"âŒ ë…¼ë¦¬í˜• ì¿¼ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {'error': f'ë…¼ë¦¬í˜• ì¿¼ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}